{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a21ac67",
   "metadata": {},
   "source": [
    "Luka Dubravica, 2025\n",
    "\n",
    "Supervised by Hardik Rajpal and Alberto Liardi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0420b644",
   "metadata": {},
   "source": [
    "### Everything At Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4265fc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from autoreject import AutoReject\n",
    "from mne.preprocessing import ICA\n",
    "from mne_icalabel import label_components\n",
    "from pyprep.prep_pipeline import PrepPipeline\n",
    "from scipy.io import loadmat, savemat\n",
    "\n",
    "mne.set_log_level(\"WARNING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a52628",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD .MAT FILE > PROCESS CHANNELS & SIGNALS > EYE EPOCHS\n",
    "\n",
    "def load_data(file_name):\n",
    "    data = loadmat(file_name)[\"EEG\"][0][0]\n",
    "    signals = data[15]/1e6\n",
    "    channels = data[21][0]\n",
    "    \n",
    "    # Extract channel information\n",
    "    channel_names = np.array([channel[0][0] for channel in channels])\n",
    "    channels_to_keep = [i for i, name in enumerate(channel_names) if name not in {\"CB1\",\"CB2\",\"EKG\"}]\n",
    "    channel_names = channel_names[channels_to_keep]\n",
    "    channel_types = [\"eeg\" if name not in {\"VEOG\",\"HEOG\"} else \"eog\" for name in channel_names]\n",
    "    channel_locs = [[channel[j][0][0] for j in range(4,7)] for channel in channels if channel[0][0] not in {\"CB1\", \"CB2\", \"EKG\"}]\n",
    "\n",
    "    # Scale coordinates cm->m and rotate them\n",
    "    channel_locs = np.array(channel_locs) / 1000\n",
    "    channel_locs = np.stack([\n",
    "        channel_locs[:, 1],\n",
    "        channel_locs[:, 0],\n",
    "        channel_locs[:, 2]\n",
    "    ], axis=1)\n",
    "\n",
    "    # Process events information\n",
    "    def extract_event_value(event): # string and integer events are stored differently\n",
    "        return event[0] if isinstance(event[0], np.str_) else event[0][0]\n",
    "\n",
    "    events = np.array([[extract_event_value(event[j]) for j in range(2)] for event in data[25][0]])\n",
    "    events = [[int(event[0]), int(event[1])] for event in events if str(event[0]).isdigit()] # drop string events\n",
    "    events = events[1:len(events)-1] # remove first and last event 17    \n",
    "    \n",
    "    # Parse events into key timestamps\n",
    "    event_labels = [event[0] % 2 for event in events] # open or closed eyes\n",
    "    switching_indeces = [i+1 for i in range(len(event_labels)-1) if event_labels[i] != event_labels[i+1]]\n",
    "    switching_tstamps = [events[0][1]] + [events[i][1] for i in switching_indeces] + [events[-1][1]]\n",
    "\n",
    "    # Slice epochs based on initial labels\n",
    "    signals = signals[channels_to_keep]\n",
    "    epochs = [signals[:, switching_tstamps[i]:switching_tstamps[i+1]] for i in range(len(switching_tstamps) - 1)]\n",
    "\n",
    "    if event_labels[0] == 0:\n",
    "        epochs_open = epochs[::2]\n",
    "        epochs_closed = epochs[1::2]\n",
    "    else:\n",
    "        epochs_closed = epochs[::2]\n",
    "        epochs_open = epochs[1::2]\n",
    "\n",
    "    return (epochs_open, epochs_closed, channel_names, channel_locs, channel_types)\n",
    "\n",
    "\n",
    "### DEFINE INFO & MONTAGE\n",
    "\n",
    "def setup_info(channel_names, channel_locs, channel_types):\n",
    "\n",
    "    # Create montage\n",
    "    montage = mne.channels.make_dig_montage(\n",
    "        ch_pos      = dict(zip(channel_names, channel_locs)),\n",
    "        coord_frame = 'head')\n",
    "\n",
    "    # Create MNE Info object\n",
    "    info = mne.create_info(\n",
    "        ch_names = channel_names.tolist(),\n",
    "        sfreq    = 500,\n",
    "        ch_types = channel_types)\n",
    "    info.set_montage(montage, match_alias={'VEOG':'eog','HEOG':'eog'})\n",
    "    print(info)\n",
    "    print()\n",
    "\n",
    "    return info\n",
    "\n",
    "\n",
    "### SCALING > HP FILTER > PREP\n",
    "\n",
    "def initial_processing(epoch, info):\n",
    "\n",
    "    # Apply high-pass filtering\n",
    "    raw_eeg = mne.io.RawArray(epoch, info)\n",
    "    hp_eeg = raw_eeg.copy().filter(l_freq=1, h_freq=100)\n",
    "\n",
    "    # Apply PREP pipeline\n",
    "    sfreq = info[\"sfreq\"]\n",
    "    prep_params = {\n",
    "        \"ref_chs\": \"eeg\",\n",
    "        \"reref_chs\": \"eeg\",\n",
    "        \"line_freqs\": []\n",
    "    }\n",
    "\n",
    "    print(\"Starting PREP...\\n\")\n",
    "\n",
    "    prep = PrepPipeline(hp_eeg, prep_params, info.get_montage(), random_state=0)\n",
    "    prep.fit()\n",
    "    hp_prep_eeg = prep.raw\n",
    "\n",
    "    print(\"\\nInitial processing complete\")\n",
    "    print(f\" > channels fixed after interpolation: {prep.interpolated_channels}\")\n",
    "    print(f\" > channels still noisy after interpolation: {prep.still_noisy_channels}\")\n",
    "\n",
    "    return hp_prep_eeg\n",
    "\n",
    "\n",
    "### EPOCH CREATION & REJECTION\n",
    "\n",
    "def epochize_and_filter(eeg):\n",
    "\n",
    "    epochs = mne.make_fixed_length_epochs(eeg, duration=4.0, preload=True, reject_by_annotation=False, proj=False)\n",
    "    n_splits = min(10, len(epochs))\n",
    "    ar = AutoReject(n_interpolate=[1,2,4,8], cv=n_splits, random_state=0) # up to 15% (high fidelity) of 64 channels\n",
    "    ar_epochs, reject_log = ar.fit_transform(epochs, return_log=True)\n",
    "\n",
    "    # ar_epochs contains all the epochs, with bad ones marked\n",
    "    # reject_log contains the bad epochs\n",
    "\n",
    "    return (epochs, ar_epochs, reject_log)\n",
    "\n",
    "\n",
    "### ICA\n",
    "\n",
    "def perform_ica(epochs, ica_method='fastica'):\n",
    "    \n",
    "    ica = ICA(n_components=0.9999999, random_state=0, method=ica_method, max_iter='auto', \n",
    "              fit_params=None if ica_method == 'fastica' else dict(extended=True))\n",
    "    ica.fit(epochs, reject_by_annotation=True)\n",
    "    \n",
    "    print()\n",
    "    print(ica)\n",
    "\n",
    "    # TEST EOG\n",
    "    eog_indices, eog_scores = ica.find_bads_eog(epochs, measure='correlation', threshold=0.6)\n",
    "    print(f\"\\nExcluded EOG components: {eog_indices}\")\n",
    "    print(f\"EOG scores: {eog_scores}\\n\")\n",
    "\n",
    "    # # TEST ECG\n",
    "    # ecg_indices, ecg_scores = ica.find_bads_ecg(epochs)\n",
    "    # print(f\"\\nExcluded ECG components: {ecg_indices}\")\n",
    "    # print(f\"ECG scores: {ecg_scores}\\n\")\n",
    "\n",
    "    # TEST MUSCLE\n",
    "    muscle_indices, muscle_scores = ica.find_bads_muscle(epochs)\n",
    "    print(f\"\\nExcluded muscle components: {muscle_indices}\")\n",
    "    print(f\"Muscle scores: {muscle_scores}\\n\")\n",
    "\n",
    "    # Label ICA components\n",
    "    icalab = label_components(epochs, ica, method='iclabel')\n",
    "\n",
    "    # “Other” is a catch-all that for non-classifiable components. \n",
    "    # We will stay on the side of caution and assume we cannot blindly remove these.\n",
    "    for idx, label in enumerate(icalab['labels']):\n",
    "        if label not in {'brain', 'other'}:\n",
    "            print(idx, icalab['y_pred_proba'][idx], \"\\t\", label)\n",
    "            ica.exclude.append(idx)\n",
    "\n",
    "    total_count = len(icalab['labels'])\n",
    "    brain_other_count = total_count - len(ica.exclude)\n",
    "    print(f\"\\nBrain & other components ratio: {brain_other_count}/{total_count}\")\n",
    "    print(f\"ICALabel exclusions: {ica.exclude}\\n\")\n",
    "\n",
    "    # Remove ICA component labeled as non-brain\n",
    "    ica_epochs = epochs.copy()\n",
    "    ica.apply(ica_epochs) # modifies in-place\n",
    "\n",
    "    return (ica, ica_epochs)\n",
    "\n",
    "\n",
    "### SAVE DATA AS FIF\n",
    "\n",
    "def save_fif(file_name, epochs_open, epochs_closed):\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    save_dir = \"export_fif\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    if epochs_open:\n",
    "        epochs_open_concat = mne.concatenate_epochs(epochs_open)\n",
    "        file_path = os.path.join(save_dir, f\"{file_name}_open_concat.fif\")\n",
    "        epochs_open_concat.save(file_path, overwrite=True)\n",
    "\n",
    "    if epochs_closed:\n",
    "        epochs_closed_concat = mne.concatenate_epochs(epochs_closed)\n",
    "        file_path = os.path.join(save_dir, f\"{file_name}_closed_concat.fif\")\n",
    "        epochs_closed_concat.save(file_path, overwrite=True)\n",
    "\n",
    "\n",
    "### SAVE DATA AS MAT\n",
    "\n",
    "def save_mat(file_name, info, epochs_open, epochs_closed):\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    save_dir = \"export_mat\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    epochs_open_data = mne.concatenate_epochs(epochs_open).get_data() if epochs_open else []\n",
    "    epochs_closed_data = mne.concatenate_epochs(epochs_closed).get_data() if epochs_closed else []\n",
    "    channel_names_data = np.array(info[\"ch_names\"], dtype=object).reshape(-1, 1)\n",
    "\n",
    "    data = {\n",
    "        'epochs_open': epochs_open_data,\n",
    "        'epochs_closed': epochs_closed_data,\n",
    "        'channel_names': channel_names_data\n",
    "    }\n",
    "\n",
    "    file_path = os.path.join(save_dir, f\"{file_name}_processed.mat\")\n",
    "    # savemat(file_path, {'data': data})\n",
    "    savemat(file_path, data)\n",
    "\n",
    "\n",
    "# LOAD DATA, CREATE MONTAGE, DEVELOP\n",
    "\n",
    "def process_file(file_name, save_file=True):\n",
    "\n",
    "    # Load data\n",
    "    file_path = os.path.join(\"depression_data\", \"matlab_files\", f\"{file_name}.mat\")\n",
    "    epochs_open, epochs_closed, channel_names, channel_locs, channel_types = load_data(file_path)\n",
    "    print(f\"File {file_name}.mat loaded\")\n",
    "\n",
    "    open_count = len(epochs_open)\n",
    "    closed_count = len(epochs_closed)\n",
    "    total_count = open_count + closed_count\n",
    "    print(f\"{total_count} epochs ({len(epochs_open)} open & {len(epochs_closed)} closed)\\n\")\n",
    "\n",
    "    info = setup_info(channel_names, channel_locs, channel_types)\n",
    "\n",
    "    # IPNYB Access\n",
    "    ipnyb_data = {}\n",
    "\n",
    "    # Process EEG\n",
    "    def process_eye_epochs(eye_epochs, type, count):\n",
    "        processed_eye_epochs = []\n",
    "        for idx, epoch in enumerate(eye_epochs):\n",
    "            if len(epoch[0]) <= 303:\n",
    "                print(\"\\n***** SKIPPING EPOCH - shorter than 304 *****\\n\\n\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                hp_prep_eeg = initial_processing(epoch, info)\n",
    "                (fixed_length_epochs, ar_epochs, reject_log) = epochize_and_filter(hp_prep_eeg)\n",
    "                (ica, ica_epochs) = perform_ica(ar_epochs, ica_method='infomax')\n",
    "                # Resetting bad channels is also important for concatenation\n",
    "                ica_epochs.interpolate_bads(reset_bads=True, method=dict(eeg=\"spline\"))\n",
    "            except Exception as e:\n",
    "                print(f\"\\n***** FAILED {type} epoch {idx + 1}/{count} (total: {total_count}) *****\")\n",
    "                print(f\"{e}\\n\\n\")\n",
    "                continue\n",
    "            \n",
    "            processed_eye_epochs.append(ica_epochs)\n",
    "            print(f\"\\n***** PROCESSED {type} epoch {idx + 1}/{count} (total: {total_count}) *****\\n\\n\")\n",
    "\n",
    "            ipnyb_local = {}\n",
    "\n",
    "            ipnyb_local[\"hp_prep_eeg\"] = hp_prep_eeg\n",
    "            ipnyb_local[\"fixed_length_epochs\"] = fixed_length_epochs\n",
    "            ipnyb_local[\"ar_epochs\"] = ar_epochs\n",
    "            ipnyb_local[\"reject_log\"] = reject_log\n",
    "            ipnyb_local[\"ica\"] = ica\n",
    "            ipnyb_local[\"ica_epochs\"] = ica_epochs\n",
    "\n",
    "            ipnyb_data[f\"{type}_{idx}\"] = ipnyb_local\n",
    "        \n",
    "        return processed_eye_epochs\n",
    "    \n",
    "    processed_epochs_open = process_eye_epochs(epochs_open, \"open\", open_count)\n",
    "    processed_epochs_closed = process_eye_epochs(epochs_closed, \"closed\", closed_count)\n",
    "\n",
    "    ipnyb_data['file_name'] = file_name\n",
    "    ipnyb_data['info'] = info\n",
    "    ipnyb_data['processed_epochs_open'] = processed_epochs_open\n",
    "    ipnyb_data['processed_epochs_closed'] = processed_epochs_closed\n",
    "\n",
    "    if save_file:\n",
    "        # Save data\n",
    "        try:\n",
    "            save_fif(file_name, processed_epochs_open, processed_epochs_closed)\n",
    "            print(f\"FIF export SUCEEDED - {file_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"FIF export FAILED - {file_name}\")\n",
    "            print(e)\n",
    "\n",
    "        try:\n",
    "            save_mat(file_name, info, processed_epochs_open, processed_epochs_closed)\n",
    "            print(f\"MAT export SUCEEDED - {file_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"MAT export FAILED - {file_name}\")\n",
    "            print(e)\n",
    "\n",
    "    return ipnyb_data\n",
    "\n",
    "\n",
    "healthy_sample = [\"509\", \"517\", \"519\", \"523\", \"533\"]\n",
    "depressed_sample = [\"559\", \"561\", \"567\", \"587\", \"624\"]\n",
    "sample = healthy_sample + depressed_sample\n",
    "\n",
    "# cca 2 hours per 10 entries (1 row)\n",
    "entire_sample = [\"507\", \"508\", \"510\", \"511\", \"512\", \"513\", \"514\", \"515\", \"516\", \"518\", \n",
    "                 \"520\", \"521\", \"522\", \"524\", \"525\", \"526\", \"527\", \"528\", \"529\", \"530\",\n",
    "                 \"531\", \"532\", \"534\", \"535\", \"536\", \"537\", \"538\", \"539\", \"540\", \"541\",\n",
    "                 \"542\", \"543\", \"545\", \"546\", \"547\", \"548\", \"549\", \"550\", \"551\", \"552\",\n",
    "                 \"553\", \"554\", \"555\", \"556\", \"557\", \"558\", \"560\", \"562\", \"563\", \"564\",\n",
    "                 \"565\", \"566\", \"568\", \"569\", \"570\", \"573\", \"574\", \"575\", \"576\", \"577\",\n",
    "                 \"578\", \"579\", \"580\", \"581\", \"582\", \"583\", \"584\", \"585\", \"586\", \"588\",\n",
    "                 \"589\", \"590\", \"591\", \"592\", \"593\", \"594\", \"595\", \"596\", \"597\", \"598\", \n",
    "                 \"599\", \"600\", \"601\", \"602\", \"603\", \"604\", \"605\", \"606\", \"607\", \"608\",\n",
    "                 \"609\", \"610\", \"611\", \"612\", \"613\", \"614\", \"615\", \"616\", \"617\", \"618\",\n",
    "                 \"619\", \"620\", \"621\", \"622\", \"623\", \"625\", \"626\", \"627\", \"628\"]\n",
    "sample = entire_sample\n",
    "sample = sample[30:]\n",
    "\n",
    "outliers_sample = [\"533\", \"535\", \"554\", \"562\", \"591\"]\n",
    "sample = outliers_sample\n",
    "\n",
    "sample_count = len(sample)\n",
    "print(f\"\\nTotal sample count: {sample_count}\")\n",
    "print(f\"Sample: {sample}\\n\")\n",
    "ipnyb = {}\n",
    "\n",
    "for idx, unit in enumerate(sample):\n",
    "    file_name = unit + \"_Depression_REST\"\n",
    "    print(f\"\\n##### {file_name} - START PROCESSING - {idx + 1}/{sample_count} #####\\n\\n\")\n",
    "    \n",
    "    try:\n",
    "        ipnyb[unit] = process_file(file_name, save_file=False)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n\\n##### {file_name} - PROCESSING FAILED - {idx + 1}/{sample_count} #####\")\n",
    "        print(f\"{e}\\n\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n\\n##### {file_name} - PROCESSING COMPLETED - {idx + 1}/{sample_count} #####\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59b8394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukad\\AppData\\Local\\Temp\\ipykernel_67668\\3863055061.py:9: RuntimeWarning: This filename (export_fif/527_Depression_REST_open_concat.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs_open_concat = mne.read_epochs(f\"export_fif/{unit}_Depression_REST_open_concat.fif\", preload=True)\n",
      "C:\\Users\\lukad\\AppData\\Local\\Temp\\ipykernel_67668\\3863055061.py:10: RuntimeWarning: This filename (export_fif/527_Depression_REST_closed_concat.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs_closed_concat = mne.read_epochs(f\"export_fif/{unit}_Depression_REST_closed_concat.fif\", preload=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukad\\mne-python\\1.9.0_0\\Lib\\site-packages\\mne_qt_browser\\_pg_figure.py:3061: RuntimeWarning: Failed to disconnect (None) from signal \"triggered()\".\n",
      "  sig.disconnect()\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "sample = [\"533\", \"535\", \"554\", \"562\", \"591\"]\n",
    "sample = [\"527\"]\n",
    "\n",
    "for unit in sample:\n",
    "\n",
    "    # Import FIF epochs_open\n",
    "    epochs_open_concat = mne.read_epochs(f\"export_fif/{unit}_Depression_REST_open_concat.fif\", preload=True)\n",
    "    epochs_closed_concat = mne.read_epochs(f\"export_fif/{unit}_Depression_REST_closed_concat.fif\", preload=True)\n",
    "\n",
    "    start = 0\n",
    "    end = 3\n",
    "    epochs_open_concat = epochs_open_concat[start:end] if len(epochs_open_concat) > end else epochs_open_concat\n",
    "    epochs_closed_concat = epochs_closed_concat[start:end] if len(epochs_closed_concat) > end else epochs_closed_concat\n",
    "\n",
    "    # epochs_open_concat.plot(n_channels=64, scalings=dict(eeg=100e-6), show_scrollbars=True, title=f\"{unit} - Open Eyes\")\n",
    "    epochs_closed_concat.plot(n_channels=64, scalings=dict(eeg=100e-6), show_scrollbars=True, title=f\"{unit} - Closed Eyes\")\n",
    "\n",
    "    # plot only 2nd, 40th and 54th channel\n",
    "    # epochs_open_concat.plot(picks=[1, 39, 53], n_channels=3, scalings=dict(eeg=100e-6), show_scrollbars=True, title=f\"{unit} - Open Eyes\")\n",
    "    # epochs_closed_concat.plot(picks=[0, 1, 38, 39, 52, 53], n_channels=6, scalings=dict(eeg=100e-6), show_scrollbars=True, title=f\"{unit} - Closed Eyes\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
